{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxuXg7P/C+3pgrA/gfyuFM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubh637/VideoQA-using-LLM/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Video question answer Bot using LLM and openAI**"
      ],
      "metadata": {
        "id": "MwT4rVY9BOzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import requests\n",
        "import os\n",
        "\n",
        "API_KEY=\"paste api key or use env to load\"\n",
        "\n",
        "# Function to extract audio from video and convert to text\n",
        "def extract_audio_text(video_path):\n",
        "    print(\"Extracting audio and transcribing...\")\n",
        "    model = whisper.load_model(\"base\")  # Use the Whisper model\n",
        "    result = model.transcribe(video_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "# Function to query OpenRouter for answers based on the transcribed text\n",
        "def ask_openrouter(query, transcript):\n",
        "    \"\"\"Get responses from OpenRouter API using DeepSeek model.\"\"\"\n",
        "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "    }\n",
        "    data = {\n",
        "        \"model\": \"deepseek/deepseek-r1:free\",  # Use the DeepSeek model\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant that answers questions based on the transcript of a video.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Here is the transcript: {transcript}. Now answer this question: {query}\"}\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "        response.raise_for_status()\n",
        "        response_data = response.json()\n",
        "        answer = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
        "        return answer\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return \"Sorry, I couldn't fetch a response from OpenRouter.\"\n",
        "\n",
        "# Main function to process the video and get answers\n",
        "def process_video(video_path):\n",
        "    # Extract text from the video\n",
        "    transcript = extract_audio_text(video_path)\n",
        "    return transcript\n",
        "\n",
        "\n",
        "def question_answer(transcript,query):\n",
        "    # Ask a question based on the transcript\n",
        "    answer = ask_openrouter(query, transcript)\n",
        "    return answer\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    while True:\n",
        "        # Ask the user for the video file path\n",
        "        video_path = input(\"Enter the path to the video file (or type 'stop' to exit): \").strip()\n",
        "\n",
        "        # Stop if the user types 'stop'\n",
        "        if video_path.lower() == \"stop\":\n",
        "            print(\"Stopping the program.\")\n",
        "            break\n",
        "\n",
        "        # Check if the video file exists\n",
        "        if not os.path.exists(video_path):\n",
        "            print(\"Error: File not found!\")\n",
        "            continue\n",
        "        # Process the video and provide an answer\n",
        "        print(\"\\n Processing the video...\")\n",
        "        transcript=process_video(video_path)\n",
        "        # Ask for the query\n",
        "        query = input(\"Ask a question based on the video: \").strip()\n",
        "\n",
        "        #taking response\n",
        "        answer = question_answer(transcript,query)\n",
        "        print(\"\\n=== Answer ===\")\n",
        "        print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyU8pb3zIk4h",
        "outputId": "4ee6aea4-7249-4883-bf5a-fa04f49417ee"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the video file (or type 'stop' to exit): /content/Adding + Auto Dismissing Alert Messages _ Complete React Course in Hindi #13.mp4\n",
            "ðŸ” Extracting audio and transcribing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask a question based on the video: make me notes \n",
            "\n",
            " Processing the video...\n",
            "\n",
            "=== Answer ===\n",
            "**Notes Based on the Video Transcript:**\n",
            "\n",
            "1. **Objective:**  \n",
            "   - Integrate Bootstrap alerts into a React app, with dismiss functionality.  \n",
            "   - Link alerts to a dark/light mode toggle feature.\n",
            "\n",
            "2. **Key Steps:**  \n",
            "   - **Alert Component Setup**  \n",
            "     - Create a functional React component (`Alert.js`).  \n",
            "     - Use Bootstrap's alert classes (e.g., `alert-primary`, `alert-success`).  \n",
            "     - Allow dismissal via Bootstrapâ€™s close button (`X`).  \n",
            "\n",
            "   - **State Management**  \n",
            "     - Use `useState` to manage the alert's visibility and content:  \n",
            "       ```javascript\n",
            "       const [alert, setAlert] = useState(null);\n",
            "       ```  \n",
            "     - Define a `showAlert` function to update the alert state with a message and type (e.g., success, danger):  \n",
            "       ```javascript\n",
            "       const showAlert = (message, type) => {\n",
            "         setAlert({ msg: message, type: type });\n",
            "       };\n",
            "       ```  \n",
            "\n",
            "   - **Props Handling**  \n",
            "     - Pass `alert` state as a prop to the `Alert` component in `App.js`.  \n",
            "     - Access props in the component using `props.alert.msg` and `props.alert.type`.  \n",
            "\n",
            "3. **Bootstrap Alert Types**  \n",
            "   - Supported types: `primary`, `success`, `warning`, `danger` (determines color and styling).  \n",
            "\n",
            "4. **Conditional Rendering**  \n",
            "   - Use the logical `&&` operator to display the alert only when `props.alert` is not `null`:  \n",
            "     ```javascript\n",
            "     {props.alert && <div className={`alert alert-${props.alert.type}`}>{props.alert.msg}</div>}\n",
            "     ```  \n",
            "   - Prevents errors when accessing `null` props initially.\n",
            "\n",
            "5. **Integration with Dark/Light Mode Toggle**  \n",
            "   - Trigger alerts when toggling themes:  \n",
            "     - Example: Call `showAlert(\"Dark mode enabled\", \"success\")` when enabling dark mode.  \n",
            "     - Similar alerts for switching to light mode.  \n",
            "\n",
            "6. **Error Handling**  \n",
            "   - Initial state of `alert` is `null` to avoid undefined prop errors.  \n",
            "   - Use defensive checks (e.g., `props.alert && ...`) to prevent crashes.  \n",
            "\n",
            "7. **Key Code Snippets:**  \n",
            "   - **Alert Component JSX**:  \n",
            "     ```javascript\n",
            "     const Alert = (props) => {\n",
            "       return (\n",
            "         props.alert && (\n",
            "           <div className={`alert alert-${props.alert.type}`}>\n",
            "             {props.alert.msg}\n",
            "             <button type=\"button\" className=\"btn-close\" onClick={() => props.setAlert(null)}></button>\n",
            "           </div>\n",
            "         )\n",
            "       );\n",
            "     };\n",
            "     ```  \n",
            "   - **App.js Integration**:  \n",
            "     ```javascript\n",
            "     function App() {\n",
            "       const [alert, setAlert] = useState(null);\n",
            "       return (\n",
            "         <div>\n",
            "           <Alert alert={alert} setAlert={setAlert} />\n",
            "           {/* Toggle button triggers showAlert() */}\n",
            "         </div>\n",
            "       );\n",
            "     }\n",
            "     ```  \n",
            "\n",
            "8. **Takeaways**  \n",
            "   - Use state to dynamically control alert visibility/content.  \n",
            "   - Bootstrap classes simplify styling for alerts.  \n",
            "   - Always handle `null` states to avoid runtime errors.\n",
            "Enter the path to the video file (or type 'stop' to exit): stop\n",
            "Stopping the program.\n"
          ]
        }
      ]
    }
  ]
}
